<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Redis</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            font-family: Arial, sans-serif;
            display: flex;
            align-items: center; /* 垂直居中 */
            justify-content: center; /* 水平居中 */
            /*height: 100vh; /* 使用视口高度作为容器高度 */
        }

        .container {
            max-width: 800px;
            padding: 20px;
            background-color: #f1f1f1;
        }

        h1 {
            margin-top: 0;
        }

        .section {
            margin-bottom: 50px;
        }
    </style>
</head>
<body>
<div class="container">
    <div class="section" id="section1">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>String</h2>
        <p>
        <p><strong>介绍：</strong>String是 redis 最基本的数据类型。可以表示任何数据，比如 jpg图像或者序列化的对象，<strong>**String的最大值能存储512MB*</strong>*。</p>

        <p><strong>实现：</strong>虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 <strong>简单动态字符串</strong>（Simple Dynamic String，<strong>SDS</strong>）。</p>

        <p>SDS 和我们认识的 C 字符串不太一样，之所以没有使用 C 语言的字符串表示，因为 SDS 相比于 C 的原生字符串：</p>

        <ul><li><strong>SDS 不仅可以保存文本数据，还可以保存二进制数据</strong>。因为 <code>SDS</code> 使用 <code>len</code> 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 <code>buf[]</code> 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。</li><li><strong>SDS 获取字符串长度的时间复杂度是 O(1)</strong>。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 <code>len</code> 属性记录了字符串长度，所以复杂度为 <code>O(1)</code>。</li><li><strong>Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出</strong>。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。</li></ul>

        <p><strong>指令：</strong>set key value | get key | 当存储的字符串是整数时可以使用 incr +1，decr -1</p>

        <p><strong>应用场景：</strong></p>

        <ol><li><p>因为 Redis 处理命令是单线程，所以执行命令的过程是原子的。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量等等。</p></li><li><p>利用 <code>SETNX key value</code> 命令可以实现一个最简易的分布式锁（存在一些缺陷，通常不建议这样实现分布式锁）。</p></li></ol>

        </p>
    </div>

    <div class="section" id="section2">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>List</h2>
        <p>
        <p><strong>介绍：</strong>List是一个按照插入顺序排序的字符串列表，可以从头部或尾部向 List 列表添加元素。</p>

        <p>列表的最大长度为 <code>2^32 - 1</code>，也即每个列表支持超过 <code>40 亿</code>个元素</p>

        <p><strong>实现：</strong>List 类型的底层数据结构是由<strong>双向链表或压缩列表</strong>实现的：</p>

        <ul><li>如果列表的元素个数小于 <code>512</code> 个（默认值，可由 <code>list-max-ziplist-entries</code> 配置），列表每个元素的值都小于 <code>64</code> 字节（默认值，可由 <code>list-max-ziplist-value</code> 配置），Redis 会使用<strong>压缩列表</strong>作为 List 类型的底层数据结构；</li><li>如果列表的元素不满足上面的条件，Redis 会使用<strong>双向链表</strong>作为 List 类型的底层数据结构；</li></ul>

        <p>但是<strong>在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表</strong>。</p>

        <p><strong>指令：</strong>LPUSH | RPUSH | LPOP | RPOP   通过 <code>LRANGE</code> 命令，你可以基于 List 实现分页查询，性能非常高！</p>

        <p><strong>应用：</strong></p>

        <p><strong>信息流展示</strong></p>

        <ul><li>举例：最新文章、最新动态。</li><li>相关命令：<code>LPUSH</code>、<code>LRANGE</code>。</li></ul>

        <p><strong>消息队列</strong></p>

        <p>Redis List 数据结构可以用来做消息队列，只是功能过于简单且存在很多缺陷，不建议这样做。</p>

        <p>相对来说，Redis 5.0 新增加的一个数据结构 <code>Stream</code> 更适合做消息队列一些，只是功能依然非常简陋。和专业的消息队列相比，还是有很多欠缺的地方比如消息丢失和堆积问题不好解决。</p>

        </p>
    </div>

    <div class="section" id="section3">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>Hash</h2>
        <p>
        <p><strong>介绍：</strong>Redis 中的 Hash 是一个 String 类型的 field-value（键值对） 的映射表，特别适合用于存储对象，后续操作的时候，你可以直接修改这个对象中的某些字段的值。</p>

        <p><strong>实现：</strong>Hash 类似于 JDK1.8 前的 <code>HashMap</code>，内部实现也差不多(数组 + 链表)。不过，Redis 的 Hash 做了更多优化。</p>

        <p><strong>指令：</strong>HSET | HGET | HMSET | HINCRBY </p>

        <p><strong>应用：</strong></p>

        <ul><li>举例：用户信息、商品信息、文章信息、购物车信息。</li><li>相关命令：<code>HSET</code> （设置单个字段的值）、<code>HMSET</code>（设置多个字段的值）、<code>HGET</code>（获取单个字段的值）、<code>HMGET</code>（获取多个字段的值）。</li></ul>

        </p>
    </div>

    <div class="section" id="section4">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>set</h2>
        <p>
        <p><strong>介绍：</strong>Redis 中的 Set 类型是一种<strong>无序集合</strong>，集合中的<strong>元素没有先后顺序但都唯一</strong>，有点<strong>类似于 Java 中的 <code>HashSet</code></strong> 。Set 轻易实现<strong>交集、并集、差集</strong>的操作，比如你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。这样的话，Set 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。</p>

        <p><strong>实现：</strong></p>

        <p><strong>指令：</strong></p>

        <p><strong>应用：</strong></p>

        <p><strong>需要获取多个数据源交集、并集和差集的场景</strong></p>

        <ul><li>举例：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集）、订阅号推荐（差集+交集） 等场景。</li><li>相关命令：<code>SINTER</code>（交集）、<code>SINTERSTORE</code> （交集）、<code>SUNION</code> （并集）、<code>SUNIONSTORE</code>（并集）、<code>SDIFF</code>（差集）、<code>SDIFFSTORE</code> （差集）。</li></ul>

        <p><strong>需要随机获取数据源中的元素的场景</strong></p>

        <ul><li>举例：抽奖系统、随机点名等场景。</li><li>相关命令：<code>SPOP</code>（随机获取集合中的元素并移除，适合不允许重复中奖的场景）、<code>SRANDMEMBER</code>（随机获取集合中的元素，适合允许重复中奖的场景）</li></ul>

        </p>
     </div>

    <div class="section" id="section5">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>zset</h2>
        <p>
        <p><strong>介绍：</strong>Sorted Set 类似于 Set，但和 Set 相比，Sorted Set 增加了一个权重参数 <code>score</code>，使得集合中的元素能够按 <code>score</code> 进行有序排列，还可以通过 <code>score</code> 的范围来获取元素的列表。有点像是 Java 中 <code>HashMap</code> 和 <code>TreeSet</code> 的结合体。</p>

        <p><strong>应用：</strong></p>

        <p>需要随机获取数据源中的元素根据某个权重进行排序的场景</p>

        </p>
    </div>


    <div class="section" id="section7">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>分布式锁</h2>
        <p>
        <ol>
        <li>普通的锁在分布式系统下不能起作用，使用SETNX命令，基于Redis的分布式锁</li><li>锁无法正常释放，出现死锁问题，为锁加过期时间</li><li>如果加锁后再加过期时间，这个操作不是原子性的，Redis提供一条语句来加过期时间SET key value EX seconds NX</li><li>设置锁过期时间也会出现问题，设置的时间短，在业务未执行完时就提前释放了锁，如果锁被提前释放了，然后被另一个线程B获取到了，此时线程A的业务执行完毕了，然后执行了<code>finally</code>代码块中的锁释放代码，这就把不属于线程A而属于线程B的锁释放掉了，解决：设置键值对中的value值为线程的唯一不重复名字</li><li>判断是否为线程自己的锁和释放锁这两个步骤不是原子性操作，这里使用lua脚本解决。</li><li>业务执行时长超过了锁的过期时长，导致锁提前被释放，业务还未执行完，我们必须能够在锁快过期的时候，适当的延长锁过期时间。可以通过定时器来解决。</li></ol>

        </p>
    </div>

    <div class="section" id="section8">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>SkipList</h2>
        <p>
        <ol><li><p><strong>结构</strong>：跳表或者跳跃表，基于有序链表，除了最下面第一层链表之外，还会产生若干层稀疏的链表，这些链表里面的指针故意跳过了一些节点，而且越高层的链表跳过的节点越多。</p></li><li><p><strong>查找</strong>：查找数据时先在最高层链表中查找，然后逐层降低，这样就跳过了一些节点，加快了查找速度。</p><ul><li><p><strong>初始化</strong>：首先，我们从跳表的头节点开始，通常是最高层级的头节点。这个头节点会指向其他层级的头节点。</p></li><li><p><strong>比较节点值</strong>：<strong>从最高层级的头节点开始，沿着每一层级向右移动，直到找到一个节点，其右侧节点的值大于或等于要查找的值。在每一层级上，我们会比较节点的值，如果当前节点的值小于目标值，则继续向右移动，否则跳转到下一层级。</strong></p></li><li><p><strong>向下层级移动</strong>：当在某一层级上找到一个节点，其右侧节点的值大于或等于目标值时，我们会将搜索范围缩小到前一个节点，并跳转到下一层级继续查找。</p></li><li><p><strong>重复比较和向下移动</strong>：在每一层级上，重复执行步骤2和步骤3，直到找到目标值或者搜索范围缩小到最底层级。</p></li><li><p><strong>线性搜索</strong>：在最底层级上，我们使用线性搜索来定位目标值的精确位置。从当前节点开始，向右移动直到找到目标值或者超过目标值。</p><p>通过以上过程，<strong>跳表可以在平均情况下以O(log n)的时间复杂度进行查找</strong>，其中n是跳表中节点的数量。由于跳表的每一层级都是有序的，它可以通过跳跃操作快速缩小搜索范围，从而提供较快的查找性能。</p></li></ul></li><li><p><strong>插入：</strong>跳表每个节点的层数是随机出来的，插入一个新节点不会影响其它节点的层数。插入操作只需要修改插入节点前后的指针，不需要对很多节点都进行调整，这样<strong>降低了插入操作的时间复杂度</strong>，这也是跳表的一个重要特性，使得它的<strong>插入性能明显优于平衡树。</strong></p></li></ol>

        </p>
    </div>

    <div class="section" id="section9">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>性能优化</h2>
        <p>
        <h3>1、避免慢查询命令</h3>

        <p>慢查询命令指的是执行较慢的命令，Redis自身提供了许多的命令，并不是所有的命令都慢，这和命令的操作复杂度有关，因此必须知道Redis不同命令的复杂度。</p>

        <p>如说，Value 类型为 String 时，GET/SET 操作主要就是操作 Redis 的哈希表索引。这个操作复杂度基本是固定的，即 O(1)。但是，当 Value 类型为 Set 时，SORT、SUNION/SMEMBERS 操作复杂度分别为 O(N+M*log(M)) 和 O(N)。其中，N 为 Set 中的元素个数，M 为 SORT 操作返回的元素个数。这个复杂度就增加了很多。Redis 官方文档中对每个命令的复杂度都有介绍，当你需要了解某个命令的复杂度时，可以直接查询。</p>

        <p>当你发现 Redis 性能变慢时，可以通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，根据请求对应的具体命令以及官方文档，确认下是否采用了复杂度高的慢查询命令。</p>

        <p>如果确实存在大量的慢查询命令，建议如下两种方式：</p>

        <p>用其他高效的命令代替：比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。</p>

        <p>当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。</p>

        <h3>2. 生产环境禁用keys命令</h3>

        <p>keys这个命令是最容易忽略的慢查询命令，因为keys命令需要遍历存储的键值对，所以操作延时很高，在生产环境使用很可能导致Redis阻塞；因此不建议在生产环境中使用keys命令。</p>

        <h3>3. keys需要设置过期时间</h3>

        <p>Redis作为内存数据库，一切的数据都是在内存中，一旦内存占用过大则会大大影响性能，因此需要对有时间限制的数据需要设置过期时间，这样Redis能够定时的删除过期的数据。</p>

        <h3>4. 禁止批量的给keys设置相同的过期时间</h3>

        <p>默认情况下，Redis 每 100 毫秒会删除一些过期 key，具体的算法如下：
            采样 ACTIVE<em>EXPIRE</em>CYCLE<em>LOOKUPS</em>PER_LOOP 个数的 key，并将其中过期的 key 全部删除；</p>

        <p>如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 <code>25%</code>` 以下。</p>

        <p>ACTIVE<em>EXPIRE</em>CYCLE<em>LOOKUPS</em>PER_LOOP 是 Redis 的一个参数，默认是 20，那么，一秒内基本有 200 个过期 key 会被删除。这一策略对清除过期 key、释放内存空间很有帮助。如果每秒钟删除 200 个过期 key，并不会对 Redis 造成太大影响。</p>

        <p>但是，如果触发了上面这个算法的第二条，Redis 就会一直删除以释放内存空间。注意，删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）。所以，一旦该条件触发，Redis 的线程就会一直执行删除，这样一来，就没办法正常服务其他的键值操作了，就会进一步引起其他键值操作的延迟增加，Redis 就会变慢。</p>

        <p>频繁使用带有相同时间参数的 EXPIREAT 命令设置过期 key 将会触发算法第二条，这就会导致在一秒内存在大量的keys过期。</p>

        <p>因此开发中一定要禁止批量的给keys设置过期时间。</p>

        <h3>5. 谨慎选择数据结构</h3>

        <p>Redis 常用的数据结构一共有五种：string、hash、list、set、zset（sorted set）。可以发现，大多数场景下使用 string 都可以去解决问题。但是，这并不一定是最优的选择。下面，简单说明下它们各自的适用场景：</p>

        <ul><li>string：单个的缓存结果，不与其他的 KV 之间有联系</li><li>hash：一个 Object 包含有很多属性，且这些属性都需要单独存储。注意：这种情况不要使用 string，因为 string 会占据更多的内存</li><li>list：一个 Object 包含很多数据，且这些数据允许重复、要求有顺序性</li><li>set：一个 Object 包含很多数据，不要求数据有顺序，但是不允许重复</li><li>zset：一个 Object 包含很多数据，且这些数据自身还包含一个权重值，可以利用这个权重值来排序
            另外Redis还提供了几种的扩展类型，如下：
            HyperLogLog：适合用于基数统计，比如PV，UV的统计，存在误差问题，不适合精确统计。
            BitMap：适合二值状态的统计，比如签到打卡，要么打卡了，要么未打卡。</li></ul>

        <h3>6. 检查持久化策略</h3>

        <p>Redis4.0之后使用了如下三种持久化策略：</p>

        <ul><li>AOF日志：一种采用文件追加的方式将命令记录在日志中的策略，针对同步和异步追加还提供了三个配置项，有兴趣的可以查看官方文档。</li><li>RDB快照：以快照的方式，将某一个时刻的内存数据，以二进制的方式写入磁盘。</li><li>AOF和RDB混用：Redis4.0新增的方式，为了采用两种方式各自的优点，在RDB快照的时间段内使用的AOF日志记录这段时间的操作的命令，这样一旦发生宕机，将不会丢失两段快照中间的数据。</li></ul>

        <p>由于写入磁盘有IO性能瓶颈，因此不是将Redis作为数据库的话（可以从后端恢复），建议禁用持久化或者调整持久化策略。</p>

        <h3>7. 采用高速的固态硬盘作为日志写入设备</h3>

        <p>由于AOF日志的重写对磁盘的压力较大，很可能会阻塞，如果需要使用到持久化，建议使用高速的固态硬盘作为日志写入设备。</p>

        <h3>8. 使用物理机而非虚拟机</h3>

        <p>由于虚拟机增加了虚拟化软件层，与物理机相比，虚拟机本身就存在性能的开销，可以使用如下命令来分别测试下物理机和虚拟机的基线性能：</p>

        <p><code>markup
            ./redis-cli --intrinsic-latency 120
        </code></p>

        <p>测试结果可以知道，使用物理机的基线性能明显比虚拟机的基线性能更好。</p>

        <h3>9. 增加机器内存或者使用Redis集群</h3>

        <p>物理机器的内存不足将会导致操作系统内存的Swap。</p>

        <p>内存 swap 是操作系统里将内存数据在内存和磁盘间来回换入和换出的机制，涉及到磁盘的读写，所以，一旦触发 swap，无论是被换入数据的进程，还是被换出数据的进程，其性能都会受到慢速磁盘读写的影响。</p>

        <p>Redis 是内存数据库，内存使用量大，如果没有控制好内存的使用量，或者和其他内存需求大的应用一起运行了，就可能受到 swap 的影响，而导致性能变慢。</p>

        <p>这一点对于 Redis 内存数据库而言，显得更为重要：正常情况下，Redis 的操作是直接通过访问内存就能完成，一旦 swap 被触发了，Redis 的请求操作需要等到磁盘数据读写完成才行。而且，和我刚才说的 AOF 日志文件读写使用 fsync 线程不同，swap 触发后影响的是 Redis 主 IO 线程，这会极大地增加 Redis 的响应时间。</p>

        <p>因此增加机器的内存或者使用Redis集群能够有效的解决操作系统内存的Swap，提高性能。</p>

        <h3>10. 使用 Pipeline 批量操作数据</h3>

        <p>Pipeline (管道技术) 是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。</p>

        <h3>11. 客户端使用优化</h3>

        <p>在客户端的使用上我们除了要尽量使用 Pipeline 的技术外，还需要注意要尽量使用 Redis 连接池，而不是频繁创建销毁 Redis 连接，这样就可以减少网络传输次数和减少了非必要调用指令。</p>

        <h3>12. 使用分布式架构来增加读写速度</h3>

        <p>Redis 分布式架构有三个重要的手段：</p>

        <ul><li>主从同步</li><li>哨兵模式</li><li>Redis Cluster 集群</li></ul>

        <p>使用主从同步功能我们可以把写入放到主库上执行，把读功能转移到从服务上，因此就可以在单位时间内处理更多的请求，从而提升的 Redis 整体的运行速度。</p>

        <p>而哨兵模式是对于主从功能的升级，但当主节点奔溃之后，无需人工干预就能自动恢复 Redis 的正常使用。</p>

        <p>Redis Cluster 是 Redis 3.0 正式推出的，Redis 集群是通过将数据分散存储到多个节点上，来平衡各个节点的负载压力。</p>

        <p>Redis Cluster 采用虚拟哈希槽分区，所有的键根据哈希函数映射到 0 ~ 16383整数槽内，计算公式：slot = CRC16(key) &amp; 16383，每一个节点负责维护一部分槽以及槽所映射的键值数据。这样 Redis 就可以把读写压力从一台服务器，分散给多台服务器了，因此性能会有很大的提升。</p>

        <p>在这三个功能中，我们只需要使用一个就行了，毫无疑问 Redis Cluster 应该是首选的实现方案，它可以把读写压力自动的分担给更多的服务器，并且拥有自动容灾的能力。</p>

        <h3>13. 避免内存碎片</h3>

        <p>频繁的新增修改会导致内存碎片的增多，因此需要时刻的清理内存碎片。
            Redis提供了INFO memory可以查看内存的使用信息，如下：</p>

        <p><code></code>`markup
            INFO memory</p>

        <h1>Memory</h1>

        <p>used<em>memory:1073741736
            used</em>memory<em>human:1024.00M
            used</em>memory<em>rss:1997159792
            used</em>memory<em>rss</em>human:1.86G
            …
            mem<em>fragmentation</em>ratio:1.86
            <code></code>`</p>

        <p>这里有一个 mem<em>fragmentation</em>ratio 的指标，它表示的就是 Redis 当前的内存碎片率。那么，这个碎片率是怎么计算的呢？其实，就是上面的命令中的两个指标 used<em>memory</em>rss 和 used_memory 相除的结果。</p>

        <p><code>markup
            mem_fragmentation_ratio = used_memory_rss/ used_memory
        </code></p>

        <p>used<em>memory</em>rss 是操作系统实际分配给 Redis 的物理内存空间，里面就包含了碎片；而 used_memory 是 Redis 为了保存数据实际申请使用的空间。</p>

        <p>那么，知道了这个指标，我们该如何使用呢？在这儿，我提供一些经验阈值：</p>

        <p>1、mem<em>fragmentation</em>ratio 大于 1 但小于 1.5。这种情况是合理的。这是因为，刚才我介绍的那些因素是难以避免的。毕竟，内因的内存分配器是一定要使用的，分配策略都是通用的，不会轻易修改；而外因由 Redis 负载决定，也无法限制。所以，存在内存碎片也是正常的。</p>

        <p>2、mem<em>fragmentation</em>ratio 大于 1.5 。这表明内存碎片率已经超过了 50%。一般情况下，这个时候，我们就需要采取一些措施来降低内存碎片率了。</p>

        <p>一旦内存碎片率过高了，此时就应该采用手段清理内存碎片了</p>

        </p>
    </div>

    <div class="section" id="section10">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>时间窗口限流</h2>
        <p>
        <p>时间窗口限流算法是一种常见的限流策略，可以使用有序集合（Zset）来实现。在Redis中，Zset是一个有序的集合，每个元素都有一个分数（score）与之关联，可以根据分数进行排序。</p>

        <p>下面是使用Zset实现时间窗口限流算法的一种方式：</p>

        <ol><li>初始化时间窗口的长度（以秒为单位）和允许的请求数量。</li><li>对于每个请求到达时，执行以下操作：<ul><li>获取当前时间戳。</li><li>使用Redis的ZADD命令将当前时间戳作为元素插入Zset，并将其分数设置为当前时间戳。</li><li>使用Redis的ZREMRANGEBYSCORE命令删除Zset中分数小于等于当前时间减去时间窗口长度的元素，即移除过期的请求记录。</li><li>使用Redis的ZCARD命令获取Zset中的元素数量，即当前时间窗口内的请求数量。</li><li>检查当前请求数量是否超过允许的请求数量。如果超过，则拒绝该请求；否则，允许该请求执行。</li></ul></li></ol>
        </p>
    </div>

    <div class="section" id="section11">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>缓存雪崩</h2>
        <p>
        <p><strong>大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机</strong>时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是<strong>缓存雪崩</strong>的问题。</p>

        <p>为了防止缓存雪崩，可以考虑以下几个策略：</p>

        <ol><li><p><em>1. <strong>均匀设置过期时间</strong></em></p><p>如果要给缓存数据设置过期时间，应该避免将大量的数据设置成同一个过期时间。我们可以在对缓存数据设置过期时间时，<strong>给这些数据的过期时间加上一个随机数</strong>，这样就保证数据不会在同一时间过期。</p><p><strong>*2. 互斥锁</strong>*</p><p>当业务线程在处理用户请求时，<strong>如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存</strong>（从数据库读取数据，再将数据更新到 Redis 里），当缓存构建完成后，再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</p><p>实现互斥锁的时候，最好设置<strong>超时时间</strong>，不然第一个请求拿到了锁，然后这个请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。</p><p><strong>3. 后台更新缓存</strong>*</p><p>业务线程不再负责更新缓存，<strong>缓存也不设置有效期</strong>，而是<strong>让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新</strong>。</p><p>事实上，缓存数据不设置有效期，并不是意味着数据一直能在内存里，因为<strong>当系统内存紧张的时候，有些缓存数据会被“淘汰”</strong>，而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程读取缓存失败就返回空值，业务的视角就以为是数据丢失了。</p><p>解决上面的问题的方式有两种。</p><p>第一种方式，后台线程不仅负责定时更新缓存，而且也负责<strong>频繁地检测缓存是否有效</strong>，检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要马上从数据库读取数据，并更新到缓存。</p><p>这种方式的检测时间间隔不能太长，太长也导致用户获取的数据是一个空值而不是真正的数据，所以检测的间隔最好是毫秒级的，但是总归是有个间隔时间，用户体验一般。</p><p>第二种方式，在业务线程发现缓存数据失效后（缓存数据被淘汰），<strong>通过消息队列发送一条消息通知后台线程更新缓存</strong>，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据，并将数据加载到缓存。这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。</p><p>在业务刚上线的时候，我们最好提前把数据缓起来，而不是等待用户访问才来触发缓存构建，这就是所谓的<strong>缓存预热</strong>，后台更新缓存的机制刚好也适合干这个事情。</p><p>#### <a href="https://www.xiaolincoding.com/redis/cluster/cache_problem.html#redis-故障宕机">#</a>Redis 故障宕机</p><p>针对 Redis 故障宕机而引发的缓存雪崩问题，常见的应对方法有下面这几种：</p><ul><li><p>服务熔断或请求限流机制；</p></li><li><p>构建 Redis 缓存高可靠集群；</p><p><em>1. 服务熔断或请求限流机制</em></p><p>因为 Redis 故障宕机而导致缓存雪崩问题时，我们可以启动<strong>服务熔断</strong>机制，<strong>暂停业务应用对缓存服务的访问，直接返回错误</strong>，不用再继续访问数据库，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务。</p><p>服务熔断机制是保护数据库的正常允许，但是<strong>暂停了业务应用访问缓存服系统，全部业务都无法正常工作</strong></p><p>为了减少对业务的影响，我们可以启用<strong>请求限流</strong>机制，<strong>只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务</strong>，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。</p><p><em>2. <strong>构建 Redis 缓存高可靠集群</strong></em></p><p>服务熔断或请求限流机制是缓存雪崩发生后的应对方案，我们最好通过<strong>主从节点的方式构建 Redis 缓存高可靠集群</strong>。</p><p>如果 Redis 缓存的<strong>主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务</strong>，避免了由于 Redis 故障宕机而导致的缓存雪崩问题。</p></li></ul></li></ol>
        </p>
    </div>

    <div class="section" id="section12">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>缓存击穿</h2>
        <p>
        <p>如果缓存中的<strong>某个热点数据过期</strong>了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是<strong>缓存击穿</strong>的问题。</p>

        <p>可以发现缓存击穿跟缓存雪崩很相似，你可以认为缓存击穿是缓存雪崩的一个子集。</p>

        <p>应对缓存击穿两种方案：</p>

        <ul><li>互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</li><li>不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；</li></ul>

        </p>
    </div>

    <div class="section" id="section13">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>缓存穿透</h2>
        <p>
        <p>缓存雪崩或击穿时，数据库中还是保存了应用要访问的数据，一旦缓存恢复相对应的数据，就可以减轻数据库的压力，而缓存穿透就不一样了。</p>

        <p>当用户访问的数据，<strong>既不在缓存中，也不在数据库中</strong>，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是<strong>缓存穿透</strong>的问题。</p>

        <p>缓存穿透的发生情况：</p>

        <ul><li>业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；</li><li><strong>黑客恶意攻击</strong>，故意大量访问某些读取不存在数据的业务；</li></ul>

        <p>应对缓存穿透的方案，常见的方案有三种。</p>

        <ul><li>第一种方案，<strong>非法请求的限制</strong>；</li><li>第二种方案，<strong>缓存空值或者默认值</strong>；</li><li>第三种方案，<strong>使用布隆过滤器快速判断数据是否存在</strong>，<strong>避免通过查询数据库来判断</strong>数据是否存在；</li></ul>

        <p>第一种方案，非法请求的限制</p>

        <p>当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API <strong>入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误</strong>，避免进一步访问缓存和数据库。</p>

        <p>第二种方案，缓存空值或者默认值</p>

        <p>当我们线上业务发现缓存穿透的现象时，<strong>可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用</strong>，而不会继续查询数据库。</p>

        <p><em>第三种方案，<strong>使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。</strong></em></p>

        <p>我们可以在<strong>写入数据库数据时，使用布隆过滤器做个标记</strong>，然后在用户请求到来时，业务线程确认缓存失效后，可以通过<strong>查询布隆过滤器快速判断数据是否存在</strong>，如果不存在，就不用通过查询数据库来判断数据是否存在。</p>

        <p>即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，<strong>Redis 自身也是支持布隆过滤器</strong>的。</p>

        <p>布隆过滤器的主要特点：</p>

        <ol><li><strong>空间效率高：</strong> 布隆过滤器使用比特数组表示集合，相比于传统的数据结构，它占用的空间非常小。</li><li><strong>查询效率高：</strong> 布隆过滤器的查询操作是常数时间复杂度，不受集合大小的影响。</li><li><strong>存在误判：</strong> 布隆过滤器存在一定的误判率，即可能把不属于集合的元素误判为属于集合，但不会漏判。</li><li><strong>不支持元素删除：</strong> 布隆过滤器不支持从集合中删除元素。</li></ol>

        <p>如何使用布隆过滤器解决缓存击穿问题：</p>

        <ol><li><strong>初始化布隆过滤器：</strong> 在系统启动时，初始化一个布隆过滤器，用于判断元素是否在缓存中。</li><li><strong>查询时先判断布隆过滤器：</strong> 在查询缓存之前，先通过布隆过滤器判断查询的key是否可能存在于缓存中。如果布隆过滤器判断不存在，直接返回缓存未命中，避免对底层存储的无效查询。</li><li><strong>存在时再查询缓存：</strong> 如果布隆过滤器判断可能存在于缓存中，再去实际查询缓存。这样可以大大减少对底层存储的压力。</li><li><strong>缓存失效时更新布隆过滤器：</strong> 当缓存失效时，更新布隆过滤器，确保下一次相同的查询能够通过布隆过滤器的判断，避免击穿问题。</li></ol>

        <p>虽然布隆过滤器存在一定的误判率，但在很多场景下，其高效的空间利用和查询速度使其成为一种有效的数据结构，特别适用于缓存击穿等需要快速判断元素是否存在的场景。</p>

        <p>所以，<strong>查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据</strong>。</p>
        </p>
    </div>

    <div class="section" id="section14">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>持久化介绍</h2>
        <p>
        <p>Redis是个<strong>基于内存的</strong>数据库。那<strong>服务一旦宕机</strong>，<strong>内存中的数据将全部丢失</strong>。</p>

        <p><strong>通常</strong>的解决方案是<strong>从后端数据库恢复这些数据</strong>，但<strong>后端数据库有性能瓶颈</strong>，如果是<strong>大数据量的恢复</strong>，1、<strong>会对数据库带来巨大的压力</strong>，2、数据库的性能不如Redis。导致程序响应慢。所以对Redis来说，<strong>实现数据的持久化，避免从后端数据库中恢复数据</strong>，是至关重要的。</p>
        </p>
    </div>

    <div class="section" id="section15">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>RDB</h2>
        <p>
        <p>RDB持久化是Redis的一种持久化方式，用于将当前内存中的数据生成快照保存到磁盘上。</p>

        <h3>触发方式：</h3>

        <h4>手动触发：</h4>

        <ol><li><p><strong><code>save</code> 命令：</strong></p><ul><li><p>阻塞当前Redis服务器，直到RDB过程完成为止，但在内存较大的情况下可能会造成长时间阻塞，不推荐在线上环境使用。</p></li></ul></li><li><p><strong><code>bgsave</code> 命令：</strong></p><ul><li>Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。</li></ul></li></ol>

        <h4>自动触发：</h4>

        <ul><li>在<code>redis.conf</code>中配置了<code>save m n</code>，即在m秒内有n次修改时，自动触发<code>bgsave</code>生成rdb文件。</li><li>主从复制时，从节点要从主节点进行全量复制时也会触发<code>bgsave</code>操作，生成当时的快照发送到从节点。</li><li>执行<code>debug reload</code>命令重新加载Redis时也会触发<code>bgsave</code>操作。</li><li>默认情况下执行<code>shutdown</code>命令时，如果没有开启AOF持久化，也会触发<code>bgsave</code>操作。</li></ul>

        <h3><code>redis.conf</code>中配置RDB：</h3>

        <ul><li><p><code>save m n</code>：在m秒内有n次修改时，自动触发<code>bgsave</code>生成rdb文件。</p></li><li><p>默认的设置为：</p><p><code>
            save 900 1
            save 300 10
            save 60 10000
        </code></p></li><li><p>以上设置表示如果在900秒内有1次修改，300秒内有10次修改，或者60秒内有10000次修改，则自动触发<code>bgsave</code>。</p></li></ul>

        <h3>优缺点：</h3>

        <p><strong>优点：</strong></p>

        <ul><li><strong>RDB文件是某个时间节点的快照</strong>，默认使用LZF算法进行压缩，<strong>压缩后的文件体积小</strong>，适用于备份、全量复制等场景。</li><li><strong>Redis加载RDB文件恢复数据速度快于AOF方式</strong>。</li></ul>

        <p><strong>缺点：</strong></p>

        <ul><li>RDB方式<strong>实时性</strong>不够，无法做到秒级的持久化。</li><li>每次调用<code>bgsave</code>都需要fork子进程，属于重量级操作，频繁执行成本较高。</li><li><strong>RDB文件是二进制的，没有可读性</strong>，不如AOF文件可读。</li><li>版本兼容性可能存在问题。</li></ul>

        <p>总的来说，RDB持久化适用于备份和全量复制等场景，但由于其实时性相对较低，Redis提供了AOF方式来解决这个问题。</p>
        </p>
    </div>

    <div class="section" id="section16">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>AOF</h2>
        <p>
        <p>RDB持久化是Redis的一种持久化方式，用于将当前内存中的数据生成快照保存到磁盘上。</p>

        <h3>触发方式：</h3>

        <h4>手动触发：</h4>

        <ol><li><p><strong><code>save</code> 命令：</strong></p><ul><li><p>阻塞当前Redis服务器，直到RDB过程完成为止，但在内存较大的情况下可能会造成长时间阻塞，不推荐在线上环境使用。</p></li></ul></li><li><p><strong><code>bgsave</code> 命令：</strong></p><ul><li>Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。</li></ul></li></ol>

        <h4>自动触发：</h4>

        <ul><li>在<code>redis.conf</code>中配置了<code>save m n</code>，即在m秒内有n次修改时，自动触发<code>bgsave</code>生成rdb文件。</li><li>主从复制时，从节点要从主节点进行全量复制时也会触发<code>bgsave</code>操作，生成当时的快照发送到从节点。</li><li>执行<code>debug reload</code>命令重新加载Redis时也会触发<code>bgsave</code>操作。</li><li>默认情况下执行<code>shutdown</code>命令时，如果没有开启AOF持久化，也会触发<code>bgsave</code>操作。</li></ul>

        <h3><code>redis.conf</code>中配置RDB：</h3>

        <ul><li><p><code>save m n</code>：在m秒内有n次修改时，自动触发<code>bgsave</code>生成rdb文件。</p></li><li><p>默认的设置为：</p><p><code>
            save 900 1
            save 300 10
            save 60 10000
        </code></p></li><li><p>以上设置表示如果在900秒内有1次修改，300秒内有10次修改，或者60秒内有10000次修改，则自动触发<code>bgsave</code>。</p></li></ul>

        <h3>优缺点：</h3>

        <p><strong>优点：</strong></p>

        <ul><li><strong>RDB文件是某个时间节点的快照</strong>，默认使用LZF算法进行压缩，<strong>压缩后的文件体积小</strong>，适用于备份、全量复制等场景。</li><li><strong>Redis加载RDB文件恢复数据速度快于AOF方式</strong>。</li></ul>

        <p><strong>缺点：</strong></p>

        <ul><li>RDB方式<strong>实时性</strong>不够，无法做到秒级的持久化。</li><li>每次调用<code>bgsave</code>都需要fork子进程，属于重量级操作，频繁执行成本较高。</li><li><strong>RDB文件是二进制的，没有可读性</strong>，不如AOF文件可读。</li><li>版本兼容性可能存在问题。</li></ul>

        <p>总的来说，RDB持久化适用于备份和全量复制等场景，但由于其实时性相对较低，Redis提供了AOF方式来解决这个问题。</p>
        </p>
    </div>

    <div class="section" id="section17">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>设置过期时间</h2>
        <p>
        <p>在Redis中，可以为键设置过期时间，使得键在一定时间后自动被删除。这是通过使用<code>EXPIRE</code>或者<code>PEXPIRE</code>命令来实现的。</p>

        <h3>使用<code>EXPIRE</code>设置过期时间：</h3>

        <p><code>bash
            EXPIRE key seconds
        </code></p>

        <p>这个命令将键 <code>key</code> 的过期时间设置为 <code>seconds</code> 秒。如果键已经有过期时间，那么会被覆盖。</p>

        <p>例如，将键 &quot;mykey&quot; 的过期时间设置为 3600 秒（1小时）：</p>

        <p><code>bash
            EXPIRE mykey 3600
        </code></p>

        <h3>使用<code>PEXPIRE</code>设置过期时间：</h3>

        <p><code>bash
            PEXPIRE key milliseconds
        </code></p>

        <p>这个命令将键 <code>key</code> 的过期时间设置为 <code>milliseconds</code> 毫秒。与<code>EXPIRE</code>不同，<code>PEXPIRE</code>接受的时间单位是毫秒。</p>

        <p>例如，将键 &quot;mykey&quot; 的过期时间设置为 60000 毫秒（1分钟）：</p>

        <p><code>bash
            PEXPIRE mykey 60000
        </code></p>

        <p>当然，在设置字符串时，也可以同时对 key 设置过期时间，共有 3 种命令：</p>

        <ul><li><code>set &lt;key&gt; &lt;value&gt; ex &lt;n&gt;</code> ：设置键值对的时候，同时指定过期时间（精确到秒）；</li><li><code>set &lt;key&gt; &lt;value&gt; px &lt;n&gt;</code> ：设置键值对的时候，同时指定过期时间（精确到毫秒）；</li></ul>

        <h3>设置过期时间的注意事项：</h3>

        <ol><li><p>过期时间是相对于键设置的时刻而言的，而不是相对于上一次访问键的时刻。</p></li><li><p>过期时间是以秒或毫秒为单位的整数值。</p></li><li><p>如果在设置过期时间后，再次对键执行写入操作（如<code>SET</code>），过期时间会被移除。</p></li><li><p>如果对已经设置过期时间的键执行读取操作，过期时间不会被移除，键仍然会在过期时间后被自动删除。</p></li></ol>

        <p>这种设置过期时间的机制非常适用于缓存场景，可以确保一些<strong>临时性的数据</strong>在一定时间后<strong>自动清理</strong>，从而避免数据的无效保留。</p>
        </p>
    </div>

    <div class="section" id="section18">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>过期删除实现</h2>
        <p>
        <p>在Redis中，<strong>过期键</strong>的判定是通过一种<strong>惰性</strong>（lazy）的<strong>策略</strong>来实现的。Redis并<strong>不会在键到达过期时间</strong>的瞬间<strong>立即删除</strong>它，而是在对该<strong>键执行读或写</strong>操作时<strong>进行判断</strong>，如果<strong>键已过期</strong>，则在<strong>操作</strong>执行<strong>之前删除</strong>该键。</p>

        <p>当我们在Redis中为一个<strong>键设置了过期时间时</strong>，Redis会将该<strong>键以及其过期时间</strong>存储到一个称为&quot;<strong>过期字典</strong>&quot;（expires dict）的数据结构中。</p>

        <ul><li>这个<strong>过期字典实际上是一个哈希表</strong>（<code>dict</code>），哈希表的使用使得在该字典中快速<strong>查找变得具有 O(1) 的时间复杂度。</strong></li><li><strong>过期字典的键是一个指针，指向某个键对象</strong>。</li><li><strong>过期字典的值</strong>是一个<code>long long</code>类型的整数，<strong>保存了键的过期时间</strong>。</li></ul>

        <p>当进行<strong>查询操作</strong>时，Redis会按照以下流程进行：</p>

        <ol><li>如果<strong>键不在过期字典中</strong>，说明键<strong>没有设置过期时间</strong>，直接<strong>正常读取</strong>键值。</li><li>如果键<strong>在过期字典</strong>中，<strong>获取该键的过期时间</strong>，并<strong>与当前系统时间进行比较</strong>。<ul><li>如果过期时间<strong>大于当前系统时间，说明键还未过期</strong>，可以正常访问。</li><li>如果过期时间<strong>小于等于当前系统时间，说明键已经过期</strong>，需要被删除。</li></ul></li></ol>

        <p>这种设计通过过期字典的哈希表结构，使得在键的过期时间管理上能够以高效的方式实现。</p>

        </p>
    </div>

    <div class="section" id="section19">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>过期删除策略</h2>
        <p>
        <p>Redis 使用定期删除（<strong>定时任务</strong>）和<strong>惰性删除</strong>（懒汉式）<strong>相结合</strong>的方式来处理<strong>过期键的删除</strong>。</p>

        <h3>1. 定期删除（定时任务）：</h3>

        <p>定期删除是通过<strong>在设置了过期时间的键中随机抽样一部分键</strong>，并<strong>检查它们是否过期</strong>，<strong>如果过期则删除</strong>。这个过程是<strong>周期性</strong>的，由Redis每隔一段时间执行一次。</p>

        <p>具体步骤如下：</p>

        <ol><li>Redis将所有设置了过期时间的键的一部分（默认是100个）进行随机抽样。</li><li>对每个被抽样的键进行过期时间检查，如果过期则删除。</li></ol>

        <p>这个定期删除策略的优点是比较简单，但缺点是不够及时，可能会导致一些过期键在周期性检查之前就一直存在。</p>

        <h3>2. 惰性删除（懒汉式）：</h3>

        <p>惰性删除是指<strong>在获取键的时候检查它是否过期</strong>，<strong>如果过期</strong>则<strong>在获取操作之前将其删除</strong>。这种方式能够确保过期键在被访问时立即删除，但也增加了每次访问的开销。</p>

        <p>具体步骤如下：</p>

        <ol><li>当对一个键进行读取或写入操作时，Redis会先检查该键是否存在于过期字典中。</li><li>如果存在于过期字典中，获取该键的过期时间。</li><li>与当前系统时间比较，如果过期则删除，然后执行相应的读或写操作。</li></ol>

        <p>这种方式的优点是能够在键被访问时立即删除，但缺点是可能增加了读写操作的开销。</p>

        <p>通过定期删除和惰性删除的相结合，Redis能够在一定程度上平衡过期键的及时性和性能开销。如果对即时性要求很高，可以通过调整配置参数来增加定期删除的频率。</p>

        </p>
    </div>

    <div class="section" id="section20">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>内存淘汰策略</h2>
        <p>
        <p>过期删除策略，是删除已过期的 key，而当 <strong>Redis 的运行内存</strong>已经<strong>超过 Redis 设置的最大内存之后</strong>，则会使用<strong>内存淘汰策略删除符合条件的 key</strong>，以此来保障 Redis 高效的运行。</p>

        <p><strong>内存淘汰策略有哪些？</strong></p>

        <p>Redis 内存淘汰策略共有八种，这八种策略大体分为<strong>「不进行数据淘汰」和「进行数据淘汰」</strong>两类策略。</p>

        <p><em>1、<strong>不进行数据淘汰的策略</strong></em></p>

        <p><strong>noeviction</strong>（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，这时如果有新的数据写入，会报错通知禁止写入，不淘汰任何数据，但是如果没用数据写入的话，只是单纯的查询或者删除操作的话，还是可以正常工作。</p>

        <p><em>2、<strong>进行数据淘汰的策略</strong></em></p>

        <p>针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。</p>

        <p><strong>在设置了过期时间的数据中进行淘汰：</strong></p>

        <ul><li><strong>volatile-random</strong>：随机淘汰设置了过期时间的任意键值；</li><li><strong>volatile-ttl</strong>：优先淘汰更早过期的键值。</li><li><strong>volatile-lru</strong>（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；</li><li><strong>volatile-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；</li></ul>

        <p><strong>在所有数据范围内进行淘汰：</strong></p>

        <ul><li><strong>allkeys-random</strong>：随机淘汰任意键值;</li><li><strong>allkeys-lru</strong>：淘汰整个键值中最久未使用的键值；</li><li><strong>allkeys-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。</li></ul>
        </p>
    </div>

    <div class="section" id="section21">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>热点key</h2>
        <p>
        <h3>5.1 数据分片</h3>

        <p>数据分片是通过将热点数据分散存储在多个Redis节点上，避免单个节点负载过高，是解决热点Key问题最常用的策略。</p>

        <p>例如，在Redis Cluster模式下，数据自动按槽位分布在多个节点上，从而实现负载均衡。对于非Cluster模式，可以通过客户端或代理层实现一致性哈希等分片算法，将数据分布在多个Redis实例上。</p>

        <h3>5.2 读写分离</h3>

        <p>读写分离可以将读操作与写操作分开处理，降低单个节点的负载。在主从复制模式下，可以将读操作分发到从节点上，从而分担主节点的压力。此外，可以使用代理层如Redis Sentinel或Twemproxy实现自动故障转移和读写分离。</p>

        <h3>5.3 缓存预热</h3>

        <p>缓存预热是指在系统启动或重启后，主动将热点数据加载到缓存中。这样，当用户访问这些热点数据时，可以直接从缓存中获取，避免对后端数据库造成压力。缓存预热可以通过定时任务或应用程序启动时加载热点数据实现。</p>

        <h3>5.4 限流</h3>

        <p>限流是通过控制请求的速率来防止系统过载。在应用层实现限流，可以有效减轻热点Key对Redis的压力。常见的限流算法有漏桶算法和令牌桶算法。</p>

        <h3>5.5 熔断降级</h3>

        <p>熔断降级是在系统出现问题时，自动降低系统功能的一种策略。在应用层实现熔断降级，可以在Redis出现热点Key问题时，快速降低对Redis的访问压力。熔断降级可以通过开源工具如Hystrix实现。</p>

        <p>通过上述策略，可以有效解决Redis的热点Key问题。然而，在实际应用中，需要根据具体业务场景和需求选择合适的策略。接下来，我们将通过实践案例来说明如何解决热点Key问题。</p>

        </p>
    </div>

    <div class="section" id="section22">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>Redis为什么这么快</h2>
        <p>
        <ol><li><p>内存存储：<strong> Redis主要</strong>将数据存储在内存中，而不是磁盘上<strong>。由于</strong>内存的读写速度比磁盘快得多**，因此Redis能够提供极高的读写性能。</p></li><li><p><strong>单线程模型：</strong> <strong>Redis采用单线程模型</strong>，即每个Redis实例都在<strong>单个线程上运行</strong>。虽然这<strong>听起来似乎会限制性能</strong>，但实际上，这样可以<strong>避免多线程之间的竞争和锁的开销</strong>，简化了系统的设计，提高了整体性能。在多核系统上，可以通过运行多个Redis实例来充分利用多核。</p></li><li><p><strong>非阻塞I/O：</strong> Redis使用了非阻塞I/O，这意味着它可以在等待数据从内存或网络中读取时执行其他操作，而不会被阻塞。这提高了系统的并发性和响应速度。</p></li><li><p><strong>数据结构：</strong> <strong>Redis</strong>支持丰富<strong>的数据结构</strong>，如字符串、列表、集合、哈希表等。这些数据结构的<strong>实现经过优化</strong>，使得Redis可以高效地执行各种操作。</p></li><li><p><strong>持久化选项：</strong> 尽管Redis主要是一个内存数据库，但它支持多种持久化选项，允许将数据定期写入磁盘以防止数据丢失。这使得Redis在需要持久性的场景中仍然表现良好。</p></li></ol>

        <p>总体而言，Redis通过将数据存储在内存中、采用单线程模型、使用非阻塞I/O等策略，以及优化的数据结构，实现了出色的性能。这使得它成为许多场景中首选的数据存储解决方案之一。</p>

        </p>
    </div>

    <div class="section" id="section23">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>布隆过滤器</h2>
        <p>
        <p>布隆过滤器（Bloom Filter）是一种空间效率高、误判率低的数据结构，主要用于<strong>判断一个元素是否属于一个集合</strong>。<strong>使用哈希函数和一个位数组实现</strong>。</p>

        <h3>基本原理：</h3>

        <ol><li><p><strong>位数组：</strong> 初始化一个位数组，所有位都初始化为 0。</p></li><li><p><strong>哈希函数：</strong> 初始化若干个哈希函数，这些<strong>哈希函数</strong>能<strong>将输入映射到位数组上</strong>的不同位置。</p></li><li><p><strong>添加元素：</strong> 当一个元素被加入集合时，<strong>通过多个哈希函数</strong>将其<strong>映射到位数组上的多个位置</strong>，并将<strong>这些位置的位设置为 1</strong>。</p></li><li><p><strong>查询元素：</strong> 当需要<strong>查询某个元素是否在集合中</strong>时，<strong>同样通过多个哈希函数</strong>将其<strong>映射到位数组上的多个位置</strong>，<strong>如果</strong>所有<strong>位置</strong>的位<strong>都为 1</strong>，则认为<strong>元素可能在集合中</strong>；如果有一个位置的位为 0，则元素肯定不在集合中。</p></li></ol>

        <h3>优点：（查询速度快 占用空间小 存在误判 不能删除）</h3>

        <ul><li><p><strong>空间效率高：</strong> 布隆过滤器只需要很少的内存空间，因为它使用位数组存储信息。</p></li><li><p><strong>查询速度快：</strong> 通过多个哈希函数，查询速度非常快。</p></li><li><p><strong>误判率低：</strong> 误判率主要取决于哈希函数的设计和位数组的大小。</p></li></ul>

        <h3>缺点：</h3>

        <ul><li><p><strong>不支持删除操作：</strong> 由于添加元素时设置了位数组的相应位置，删除元素会影响其他元素的判断结果，因此不支持删除操作。</p></li><li><p><strong>存在误判：</strong> 有一定的概率存在误判，即判断某个元素在集合中时，可能存在一定的误报率。</p></li></ul>

        <h3>应用场景：</h3>

        <ul><li><p><strong>缓存击穿：</strong> 用于快速判断某个查询是否存在于缓存中，避免对数据库进行频繁查询。</p></li><li><p><strong>防止爬虫：</strong> 用于检查某个 URL 是否已经被爬虫爬取过，减少重复爬取。</p></li><li><p><strong>单词拼写检查：</strong> 用于检查输入的单词是否拼写正确。</p></li><li><p><strong>安全领域：</strong> 用于判断一个 IP 是否是恶意攻击。</p></li></ul>

        <p>实现布隆过滤器的关键在于选择合适的哈希函数和位数组大小，以及根据实际情况合理估计误判率。</p>

        <hr/>

        <p>选择布隆过滤器的<strong>位数组大小</strong>需要根据预计的数据量和容忍的误判率来进行权衡。位数组的大小（通常用 m 表示）和哈希函数的数量（通常用 k 表示）是布隆过滤器的两个关键参数。</p>

        <p>误判率（False Positive Rate）和位数组大小、哈希函数数量之间的关系可以通过以下公式估计：</p>

        <p>[ \text{False Positive Rate} = \left(1 - e^{-\frac{kn}{m}}\right)^k ]</p>

        <p>其中：</p>

        <ul><li>( n ) 是要插入的元素数量。</li><li>( m ) 是位数组的大小。</li><li>( k ) 是哈希函数的数量。</li><li>( e ) 是自然对数的底数。</li></ul>

        <p>要选择合适的位数组大小，可以通过以下步骤进行估算：</p>

        <ol><li><p><strong>估算数据量 ( n )：</strong> 预估系统中可能出现的不同元素的数量。</p></li><li><p><strong>估算允许的误判率 ( \text{False Positive Rate} )：</strong> 根据业务需求和对误判率的容忍程度，选择一个合适的误判率。</p></li><li><p><strong>选择哈希函数数量 ( k )：</strong> 根据 ( \text{False Positive Rate} ) 的公式，选择合适的哈希函数数量。常见的选择是 ( k = \frac{m}{n} \times \ln(2) )。</p></li><li><p><strong>计算位数组大小 ( m )：</strong> 使用 ( m = -\frac{n \times \ln(\text{False Positive Rate})}{(\ln(2))^2} ) 计算位数组大小。</p></li></ol>

        <p>需要注意的是，选择较小的位数组大小和哈希函数数量可以减小空间占用，但可能增加误判率。选择过大的位数组大小和哈希函数数量会增加空间占用，但可以降低误判率。</p>

        <p>根据实际情况，可以进行多次试验和调整以找到满足性能和误判率要求的最佳参数。</p>

        </p>
    </div>

    <div class="section" id="section24">
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2>SkipList</h2>
        <p>

        </p>
    </div>
</div>
</body>
</html>