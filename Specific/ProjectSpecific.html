<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>校园集市</title>
  <style>
    body {
      margin: 0;
      padding: 0;
      font-family: Arial, sans-serif;
      display: flex;
      align-items: center; /* 垂直居中 */
      justify-content: center; /* 水平居中 */
      /*height: 100vh; /* 使用视口高度作为容器高度 */
    }

    .container {
      max-width: 800px;
      padding: 20px;
      background-color: #f1f1f1;
    }

    h1 {
      margin-top: 0;
    }

    .section {
      margin-bottom: 50px;
    }
  </style>
</head>
<body>
<div class="container">
  <div class="section" id="section1">
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <h2>为什么选用微服务架构</h2>
    <p>

    <p>单体应用过度膨胀会带来一些问题：</p>

    <p>微服务架构和单体架构都有各自的优缺点。下面是相比于微服务架构，单体架构可能存在的一些缺点：</p>

    <ol><li><strong>复杂性：</strong> 单体架构通常是一个大型的、紧密耦合的应用程序，其中<strong>所有的功能模块都集中在一起</strong>。随着业务的增长，代码规模可能会急剧增加，导致<strong>复杂性和维护成本的上升</strong>。这使得理解和修改单体应用变得更加困难。</li><li><strong>可伸缩性受限：</strong> 单体应用的可伸缩性通常受限于硬件资源的限制。如果需要<strong>增加某个特定功能的处理能力</strong>，<strong>必须要对整个应用进行复制或扩展，而不仅仅是扩展特定功能模块。</strong></li><li><strong>部署风险：</strong> 由于单体应用中所有组件紧密耦合在一起，当进行更新或者修复时，可能会导致整个应用出现故障。这样的风险会使得部署变得更加困难和棘手。</li><li><strong>可靠性：</strong> <strong>单体应用的可靠性可能会受到威胁。一旦应用中的一个组件出现故障，整个应用可能会崩溃或变得不可用。</strong></li><li><strong>灵活性和快速迭代：</strong> <strong>在单体架构中，一个小的变更可能需要重新构建整个应用并进行完整的测试</strong>。这可能导致开发周期的延长，从而降低了快速迭代和发布的能力。</li></ol>

    <p>值得注意的是，单体架构在某些情况下仍然是一个合理的选择，尤其是在项目起初规模较小、功能简单、团队较小且资源有限的情况下。但随着业务的增长和复杂性的提升，许多组织选择将应用迁移到微服务架构，以解决上述问题并获得更多的灵活性和可扩展性。</p>

    </p>
  </div>


  <div class="section" id="section2">
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <h2>为什么选择MongoDB</h2>
    <p>
    <p>由于评论的特殊性，它需要如下能力:</p>

    <pre> 【字段扩展】不同的评论存储的字段有一定差异，需要支持动态的自动扩展。

  【海量数据】作为公司中台服务，数据量随着业务方的增多成倍增长，需要具备快速便捷的水平扩展和迁移能力。

  【高可用】作为中台产品，需要提供快速和稳定的读写能力，能够读写分离和自动恢复

  而评论业务不涉及用户资产，对事务的要求性不高。因此我们选用了MongoDB集群作为了最底层的数据存储方式。</pre>

    </p>
  </div>

  <div class="section" id="section3">
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <h2>Nacos和Eureka</h2>
    <p>
    <p>采用Eureka方案的考虑</p>

    <ul><li>想用Spring Cloud原生全家桶</li><li>想用本地文件和Git作为配置管理的,将配置与服务分开管理</li><li>考虑短期的稳定性</li></ul>

    <p>采用Nacos方案的考虑</p>

    <ul><li>想在线对服务进行上下线和流量管理</li><li>不想采用MQ实现配置中心动态刷新</li><li>不想新增配置中心生产集群</li><li>考虑引入Spring Cloud Alibaba生态</li></ul>

    </p>
    <p>服务健康检查：Euraka 使用时需要显式配置健康检查支持；Zookeeper、Etcd 则在失去了和服务进程的连接情况下任务不健康，而 Consul 相对更为详细点，比如内存是否已使用了90%，文件系统的空间是不是快不足了。
      多数据中心：Consul 和 Nacos 都支持，其他的产品则需要额外的开发工作来实现。
      KV 存储服务：除了 Eureka，其他几款都能够对外支持 k-v 的存储服务，所以后面会讲到这几款产品追求高一致性的重要原因。而提供存储服务，也能够较好的转化为动态配置服务哦。
      CAP 理论的取舍：</p>

    <p>Eureka 是典型的 AP，Nacos可以配置为 AP，作为分布式场景下的服务发现的产品较为合适，服务发现场景的可用性优先级较高，一致性并不是特别致命。
      而Zookeeper、Etcd、Consul则是 CP 类型牺牲可用性，在服务发现场景并没太大优势；</p>

    <p>Watch的支持：Zookeeper 支持服务器端推送变化，其它都通过长轮询的方式来实现变化的感知。
      自身集群的监控：除了Zookeeper和Nacos，其它几款都默认支持 metrics，运维者可以搜集并报警这些度量信息达到监控目的。
      Spring Cloud的集成：目前都有相对应的 boot starter，提供了集成能力。</p>

    <p>作者：楼仔
      链接：https://juejin.cn/post/7068065361312088095
      来源：稀土掘金
      著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
  </div>

  <div class="section" id="section4">
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <h2>Nginx和Gateway</h2>
    <p>
    <p>一听到网关，首先想到的就是Nginx。</p>

    <p><strong>Nginx 和 Gateway 在微服务体系中的分工是不一样的。Gateway 作为更底层的微服务网关，通常是作为外部 Nginx 网关和内部微服务系统之间的桥梁，起了这么一个承上启下的作用。</strong>在大型微服务应用中，我们往往会搭建<strong>多个网关组件</strong>，这些网关的应用场景也各有不同，Gateway在微服务架构中扮演的角色是<strong>“微服务网关”</strong></p>

    <p>使用最广泛而且最经济实惠的技术选型就是Nginx 反向代理。因为它拥有超强的<strong>并发能力</strong>，而且很<strong>节省内存</strong>资源。</p>

    <p>请求经过了多级网关服务的转发，抵达了最后的微服务层。在这一层上，Gateway 就需要出马来负责请求转发了。</p>

    <p>Gateway 既然叫“微服务网关”，就说明它自己就是一个微服务。换句话说，它也是 Nacos 服务注册中心的一员。既然 Gateway 能连接到 Nacos，那么就意味着它可以轻松获取到 Nacos 中所有服务的注册表。这样一来，Gateway 就可以根据本地的路由规则，将请求精准无误地送达到每个微服务组件中。</p>

    <p>使用 Gateway 有一个显而易见的好处，那就是高可扩展性。当你对后台的微服务集群做扩容或缩容的时候，Gateway 可以从 Nacos 注册中心轻松获取所有服务节点的变动，不需要任何额外的配置，一切都在无感知的情况下自然而然地发生。</p>

    </p>
  </div>

  <div class="section" id="section5">
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <h2>登录实现</h2>
    <p>
    <p>客户端可以匿名访问，但是如果需要点赞评论或者查看个人中心等行为，是需要登录的，这时会自动跳出来一个登录界面。</p>

    <p>支持微信OAuth2三方认证的方式登录</p>

    <p>首先设计了一个用户表，用户的账号密码头像注册时间等字段，当前端提交请求时，请求体以JSON形式提交账号密码，请求先到后端Gateway网关，网关判断登录请求是不需要校验Token的，所以直接放行。请求被转发到用户服务，先针对参数进行合法性校验，是否非空是否合法，如果有问题则直接返回登录失败信息。</p>

    <p>没问题，判断账号密码是否频繁登录，用户账号密码错误频繁的进行登录，或者是非法、恶意的请求，在这里我借助Redis的ZSet数据类型设计了一个<strong>时间窗口限流</strong>算法，对这种操作进行限制，减少数据库的压力。</p>

    <p>如果没有限流，就查询用户数据，判断用户是否存在，如果不存在就返回登录失败。如果存在，就继续校验密码，使用了加随机盐的工具类BCrypt实现，它的安全度更高。</p>

    <p>如果密码校验通过，就封装用户数据到JWT Token的载荷中，然后返回给前端。</p>

    <p>以后前端就会带着这个Token访问其他资源。在网关处，会对Token进行校验，对于受访问资源判断是否携带Token，以及Token是否有效，Token没问题就将请求传递给后面的服务。</p>

    </p>
  </div>

  <div class="section" id="section7">
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <h2>点赞阅读不喜欢</h2>
    <p>
    <p><strong>点赞、阅读、不喜欢这样的用户行为</strong>，放在<strong>用户行为微服务</strong>中实现，。基本的CRUD操作，<strong>设计相应的中间表</strong>，<strong>记录用户</strong>对某一篇文章的点赞、阅读、不喜欢的<strong>情况</strong>。<br/>
      当用户<strong>触发了</strong>点赞、阅读、不喜欢等用户行为时，由用户行为微服务处理，<strong>新数据先更新到 Redis</strong>.这里使用到了 <strong>Zset类型</strong>，将用户行为封装为JSON 格式，作为值，<strong>将时间戳作为 score分值</strong>.<strong>更新到 Redis 成功后，立刻响应前端，前端可以先标注点赞、阅读、不喜欢成功。</strong>可能会出现用户点赞后，立刻退出文章界面，点击个人中心，查询点赞记录，可能会出现几秒中看不到点赞记录的情况，但是无所谓，这种情况出现的可能性较少，就算有人故意点赞完毕立刻退出文章列表、打开个人中心、查看点赞记录，可能会看不到刚才点赞的结果，但这种情况我们业务上根本就不在意。<br/>
      <strong>后续</strong>每隔10秒钟，使用XXL-JOB定时任务<strong>，以异步的方式将 Redis 中的数据进行处理</strong>:<br/>
      <strong>先更新到 MySQL的数据表中，记录用户的行为的数据</strong><br/>
      <em>将这3中用户行为数据发送到 Kafka中，因为在文章热度计算流程中，会监听用户的点赞和阅读行为数据，而不喜欢行为数据需要被大数据系统采集;</em><br/>
      <strong>之后，更新 Redis，我们使用hash 类型</strong>，<strong>记录每一个用户对文章产生的行为数据</strong>。这样，当用户<strong>重新打开以前阅读过的文章</strong>，只需要<strong>查询 Redis</strong>，就可以获取到<strong>用户对应的行为数据</strong>，<strong>比如查询用户是否之前针对这篇文章点赞、不喜欢。</strong>每次<strong>查询完毕</strong>后，<strong>重置用户</strong>在 Redis 的行为<strong>数据的TTL过期时间</strong>，<strong>默认设置过期时间为10天</strong>。用户<strong>长期不使用</strong>App，就先把<strong>缓存中的数据自动清理</strong>掉，等<strong>下次查询没有时，重新从MySQL中缓存</strong>。
      还有就是在<strong>用户发生点赞</strong>行为后，会同步<strong>更新</strong>一下用户的<strong>点赞列表缓存</strong>，使用的是redis <strong>list 类型实现</strong>的。
      将来用户查询对某一篇文章的用户行为数据，以及用户的阅读记录，用户的点赞记录，直接从 Redis 中缓存返回就可以了。</p>

    </p>
  </div>

   <div class="section" id="section8">
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
    <h2>文章评论</h2>
    <p>
     <p><strong>文章评论单独设计了评论微服务进行实现</strong>。<strong>所有的评论数据</strong>包括评论回复，评论点赞，都是<strong>保存在了 MongoDB 当中。</strong></p>

     <p>选择MongoDB的主要原因：<strong>文章评论算的上有点并发需求</strong>，最好是基于内存实现并且采用非结构化数据。
       题外话: mongodb 的数据是存储在硬盘上的,需要经常读取的数据会被加载到内存中,这样提高查询效率,所谓内存数据映射,所以 mongodb 本身很吃内存。</p>

     <p><strong>不选择Redis和MySQL的原因：</strong>评论管理模块，如果使用 Redis KEY VALUE这种结构实现，不能很好的满足基础的 CRUD 操作，比如: 评论基本信息查询、分页展示、时间排序、评论状态修改等等，如果<strong>使用传统的关系型数据库实现的话，会涉及到频繁的多表连接查询，在高并发场景下非常消耗性能</strong>。综合考虑下，使用MongoDB 进行实现，</p>

     <p><strong>具体实现：</strong>我们在MongoDB 中创建了4张表 评论表、评论点赞表、评论回复表、 评论回复表、评论回复点赞表
       ap<em>comment ap</em>comment like  ap<em>comment</em>repay  ap_comment repay like </p>

     <p><strong>查询文章评论流程，是一个分页查询，默认查询前 10条评论</strong>，使用MongoDB 的管道聚合查询的方式，将评论点赞、评论回复信息一并查询出来，返回给前端展示。后续用户发表评论，评论回复，评论点赞，都是针对MondoDB 中的数据进行更新的。</p>

    </p>
  </div>

   <div class="section" id="section9">
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
    <h2>文章热度计算</h2>
    <p>
     <p>推荐算法的好坏，则不仅密切关系着内容对用户的吸引程度，也同时反应了产品对内容的分发能力。</p>

     <p>文章热度我们主要是根据用户的阅读、点赞、评论、收藏这4 种行为进行计算在文章表中，我们设计了相应的点赞数量、收藏数量、评论数量和阅读数量进行记录:</p>

     <p>当用户针对某一篇文章发生了这4种<strong>行为后不仅更新数据库文章表中的字段</strong>，同时还要根据这4种行为数据，进行<strong>文章热度的统计计算</strong>求出来哪些文章是比较火。统计的需求:针对5天以内发布的文章进行统计，统计普通频道和热点频道当中，最热门的30条文章数据。防止很久以前一些老的文章，长期占据榜首的情况出现。统计的方式:<strong>我们分为定时计算和实时计算两种方式，不管是哪种方式，统计的结果是不会保存在MySQL，而是保存在 Redis</strong>，因为每天凌晨2点，都会重置热点数据，说白了<strong>每天都会重新查询 MySQL重新开始新一轮的热点文章计算</strong>。所以说就没必要把文章热度数据存在MySQL 当中
       定时计算主要是借助XXL-JOB，每天2点的时间，执行计划任务，进行统计，主要是针对5天以内发布的文章做一个统计，作为每天新一轮的热点文章热度初始数据。实时计算是借助 Kafka Stream 实现的，<strong>主要是针对当天新产生的用户行为，进行实时计算.业务上，我们认为当天发布的文章，发生的用户行为所占的权重分值比重会高一点，避免一些老的文章一直霸榜的情况出现。</strong>实时计算出来的分值，会基于每天定时计算的结果进行累计，两种计算方式结合在一起，实现这个业务需求统计的权重:
       <strong>用户不同的行为，权重不一样:阅读权重:1，点赞权重:3，评论权重:5，收藏权重8当天发布的文章，对应的用户行为权重得分是非当天发布的文章权重得分的3 倍。</strong>这块实现方式是主要是在实时计算中实现的。</p>

     <p>牛顿冷却定律 <strong>热度 = 初始热度 + 互动热度 – 随时间衰减的热度</strong></p>

     <p>定时计算：</p>

     <p>每天凌晨两点，执行定时任务针对前5天的文章，进行分值统计，这里的定时任务是使用XXL-JOB实现的。
       因为文章的阅读、点赞、评论、收藏这些数据都在文章数据表中存在的，所以这个计算逻辑特别简单:</p>

     <ol><li>按照发布时间字段，查询出来最近5天发布的文章，并且文章状态处于正常状态</li><li>根据文章的4 项行为数据，结合它们对应的权重分值，做个加法计算，计算出来每篇文章的最重权重分值，并将所有文章的分值结果保存在一个 List 集合中</li><li>远程调用媒体服务，得到所有的频道集合，遍历频道列表，在每次循环中，再次使用流式编程的方式，遍历前面计算出来的文章分值集合，比如:调用fiter 方法进行过滤，将每一篇文章归类到对应的频道下。然后调用 sot 方法进行排序，按照每篇文章的分值进行降序排序。最后，判断一下当前频道下的文章数量是否大于 30，如果大于30 篇文章，就截取前30篇文章，作为当前频道的热点文章，并将他们缓存到 Redis 中，把频道ID作为key，把热点文章列表作为值</li><li>求出所有文章热点排名前30的文章，并缓存到Redis 中，这些数据作为[热点栏目)中的热点文章进行推荐。
       我们使用Redis进行缓存热点文章数据以后，再针对热点文章查询时，直接从 Redis 返回就可以了。包括后续实时计算的时候，针对当天的文章进行计算，只需要更新 Redis 中的数据即可。</li><li>最后，设计了XXL-JOB 定时调度，每天凌晨2点，执行定时任务，将前5天的数据重新计算，最终的热点文章重新缓存到 Redis。</li></ol>

     <p>实时计算：</p>

     <p>还有一个实时计算，主要是借助 Kafka Stream 实现的主要是针对当天新发生的用户行为进行计算，并基于定时任务计算出来的结果做一个加法计算，得到最新的文章热度数据。</p>

     <p>我先给您说一下实时计算和定时计算的区别吧。这两种方式，计算的数据，都不会持久化保存到 MySQL，而是不断动态变化的首先是每天凌晨2点执行定时计算，作为当天的基础数据，缓存在Redis 中。然后当天发生的新增用户行为，会被发送到 Kafka 的热点文章分值主题中保存。</p>

     <p>最终，在文章微服务中，定义了行消费处理。
       Kafka Stream 负责针对队列中不断生产出来的消息，进行用户行为消费处理</p>

     <p>处理流程：</p>

     <ol><li><p>重置消息 kv 格式:定义Stream 对象时，重置关于消息的 key value 数据，将文章id作为 key，将消息类型和行为分值作为值，比如说: key 是1234，value 是likes:3，代表点赞行为加3分。</p></li><li><p>分组:在后续的处理中，我会按照 key 进行分组，同一篇文章的行为数据，分到一个组
       里面，这样我就可以在聚合的时候，针对同一篇文章进行聚合。</p></li><li><p>聚合: 聚合是发生在同一个分组内部的，也就是说，针对同一篇文章发生的不同行为进行聚合计算，比如:针对点赞加3分，如果用户取消点赞，那就减3分。这样就能算出来，在某一个时间窗口期内，用户针对同一篇文章，发生的各种行为，得出的最终分数</p></li><li><p>输出: 最后，再将聚合后的结果数据，转换为 key value 的形式，输出到热点文章处理完毕的主题中。</p><p>消息处理完毕后，还需要定义一个消费者，消费处理完毕的结果。</p></li></ol>

     <p>这个消费者也是定义在文章微服务当中的，当接收到 Kafka Stream 输出的[文章统计结果消息]，则进行更新操作:
       首先，先更新文章数据表中的用户行为记录，比如: 阅读、点赞、收藏、评论的数量</p>

     <p>然后我会判断一下当前文章是否是当天发布的文章，如果是当天发布的文章，则分数值乘以3，然后更新到 Redis 中。
       比如说，用户收藏了非当天发布的文章，分值权重加8分，而收藏了当天发布的文章，分值权重加24 分
       如果不是当天发布的文章，则分数值按照正常的分值进行存储
       最后，我会将热点数据，更新到 Redis 缓存中，主要是更新两个项目，分别是:更新当前文章所属频道的热点文章数据
       更新热门推荐栏目的热点文章数据
       如果当前文章是热门数据，那么它一定在 Redis 缓存中，所以只需要更新 Redis 中的分值，做一个加法计算即可
       如果当前文章，不是热门数据，但是它的分值经过计算，大于热门文章的最后一篇文章的分值，那么当前文章就作为新的热点文章替换掉原先分值最低的热门文章就可以了
       流式计算进行统计，并且将最新的分值更新到 Redis 中，说白了其实就是基于每天定时统计出来的基础数据进行动态的调整</p>

    </div>

   <div class="section" id="section10">
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
    <h2>微信登录</h2>
    <p>
     <p>OAuth是一个开放授权标准，允许用户让第三方应用访问该用户在其它网站上存储的资源，而无需将用户名和密码提供给第三方应用。</p>

     <p>提供一个令牌，而不是用户名和密码来访问他们存放在特定服务提供者的数据。</p>

     <p>我们这里主要模拟使用OAuth2.0，用户通过扫描我们网页应用的二维码并进行授权登录，步骤：</p>

     <ol><li><p>在<strong>微信开放平台注册开发者帐号</strong>，并拥有一个已审核通过的网站应用，并获得相应的AppID和AppSecret，申请微信登录且通过审核后，可开始接入流程。</p></li><li><p><strong>提交网站应用审核</strong>，等微信审核通过，我们即可<strong>获得我们需要的网页应用的appid和AppSecret</strong>，<strong>并配置后回调的域名</strong>。</p></li><li><p>由于我们这里要<strong>使用微信登录的接口</strong>，所以我们还需要向微信提出认证，只有认证了才能使用微信那些高级的接口。</p></li></ol>

     <p>授权流程说明：</p>

     <p>微信OAuth2.0授权登录让微信用户使用微信身份安全登录第三方应用或网站，在微信用户授权登录已接入微信OAuth2.0的第三方应用后，第三方可以获取到用户的接口调用凭证（access<em>token），通过access</em>token可以进行微信开放平台授权关系接口调用，从而可实现获取微信用户基本开放信息和帮助用户实现基础开放功能等。</p>

     <p><strong>微信OAuth2.0授权登录目前支持authorization_code模式</strong></p>
       <p><strong>授权码</strong></p>
       <p>1、授权码</p>

       <p>OAuth2.0四种授权中授权码方式是最为复杂，但也是安全系数最高的，比较常用的一种方式。这种方式适用于兼具前后端的Web项目，因为有些项目只有后端或只有前端，并不适用授权码模式。</p>

       <p>以用WX登录掘金为例，详细看一下授权码方式的整体流程</p>

       <p>用户选择WX登录掘金，掘金会向WX发起授权请求，接下来 WX询问用户是否同意授权（常见的弹窗授权）。response<em>type 为 code 要求返回授权码，scope 参数表示本次授权范围为只读权限，redirect</em>uri 重定向地址。</p>

       <p>用户同意授权后，WX 根据 redirect_uri重定向并带上授权码。</p>

       <p>当掘金拿到授权码（code）时，带授权码和密匙等参数向WX申请令牌。grant<em>type表示本次授权为授权码方式 authorization</em>code ，获取令牌要带上客户端密匙 client_secret，和上一步得到的授权码 code。</p>

       <p>最后 WX 收到请求后向 redirect<em>uri 地址发送 JSON 数据，其中的access</em>token 就是令牌。</p>

       <p>拿到令牌可以调用 WX API 请求数据了，那令牌该怎么用呢？</p>

       <p>每个到达WX的请求都必须带上 token，将 token 放在 http 请求头部的一个Authorization字段里。</p>

     <p>第三方发起微信授权登录请求，微信用户允许授权第三方应用后，微信会拉起应用或重定向到第三方网站，并且带上授权临时票据code参数；</p>

     <ol><li><p>通过code参数加上AppID和AppSecret等，通过API换取access_token；</p></li><li><p>通过access_token进行接口调用，获取用户基本数据资源或帮助用户实现基本操作。</p></li></ol>

     <p><strong>当我们通过微信的认证，获取到了appid和AppSecret，并配置了回调的域名</strong>。我们就已经可以获取属于我们网页的二维码了，获取的方式很简单，<strong>只需打开一个微信的链接，加上我们的appid和回调域名即可在网页上面打开二维码</strong>，<strong>用户用微信客户端扫码并授权登录之后即会跳转到我们配置的回调域名下</strong>。</p>

     <p>通过使用微信客户端的扫一扫功能，扫描该二维码，即会跳转到上面填写redirect_uri所在的地址上。假如用户同意授权，这里就获得了微信返回的code参数了。</p>

     <p>假如前面已经获得code。我们可以<strong>通过code参数去获取用户openid和access_token,进而获得用户的信息。</strong></p>

     <p>通过access_token获取用户的基本信息</p>

     <p>ttps://api.weixin.qq.com/sns/userinfo?access<em>token=ACCESS</em>TOKEN&amp;openid=OPENID</p>

     <ol><li><p>普通用户的标识，对当前开发者账号唯一</p></li><li><p>普通用户昵称</p></li><li><p>普通用户性别</p></li><li><p>普通用户个人资料填写的省份</p></li><li><p>普通用户个人资料填写的城市</p></li><li><p>国家</p></li><li><p>用户头像</p></li></ol>

    </p>
  </div>

   <div class="section" id="section11">
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
    <h2>JWT</h2>
    <p>
     <p>一、跨域认证的问题
       互联网服务离不开用户认证。一般流程是下面这样。</p>

     <p>1、用户向服务器发送用户名和密码。
       2、服务器验证通过后，在当前对话（session）里面保存相关数据，比如用户角色、登录时间等等。
       3、服务器向用户返回一个 session<em>id，写入用户的 Cookie。
         4、用户随后的每一次请求，都会通过 Cookie，将 session</em>id 传回服务器。
       5、服务器收到 session_id，找到前期保存的数据，由此得知用户的身份。
       这种模式的问题在于，扩展性（scaling）不好。单机当然没有问题，如果是服务器集群，或者是跨域的服务导向架构，就要求 session 数据共享，每台服务器都能够读取 session。</p>

     <p>举例来说，A 网站和 B 网站是同一家公司的关联服务。现在要求，用户只要在其中一个网站登录，再访问另一个网站就会自动登录，请问怎么实现？</p>

     <p>一种解决方案是 session 数据持久化，写入数据库或别的持久层。各种服务收到请求后，都向持久层请求数据。这种方案的优点是架构清晰，缺点是工程量比较大。另外，持久层万一挂了，就会单点失败。</p>

     <p>另一种方案是服务器索性不保存 session 数据了，所有数据都保存在客户端，每次请求都发回服务器。JWT 就是这种方案的一个代表。</p>

     <p>二、JWT 的原理
       JWT 的原理是，服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样。</p>

     <p>javascript { &quot;姓名&quot;: &quot;张三&quot;, &quot;角色&quot;: &quot;管理员&quot;, &quot;到期时间&quot;: &quot;2018年7月1日0点0分&quot; }
       以后，用户与服务端通信的时候，都要发回这个 JSON 对象。服务器完全只靠这个对象认定用户身份。为了防止用户篡改数据，服务器在生成这个对象的时候，会加上签名（详见后文）。</p>

     <p>服务器就不保存任何 session 数据了，也就是说，服务器变成无状态了，从而比较容易实现扩展。</p>

     <p>三、JWT 的数据结构
       实际的 JWT 大概就像下面这样。</p>

     <p>它是一个很长的字符串，中间用点（.）分隔成三个部分。注意，JWT 内部是没有换行的，这里只是为了便于展示，将它写成了几行。</p>

     <p>JWT 的三个部分依次如下。</p>

     <p>Header（头部）
       Payload（负载）
       Signature（签名）
       写成一行，就是下面的样子。</p>

     <p>javascript Header.Payload.Signature</p>

     <p>下面依次介绍这三个部分。</p>

     <p>3.1 Header
       Header 部分是一个 JSON 对象，描述 JWT 的元数据，通常是下面的样子。</p>

     <p>javascript { &quot;alg&quot;: &quot;HS256&quot;, &quot;typ&quot;: &quot;JWT&quot; }
       上面代码中，alg属性表示签名的算法（algorithm），默认是 HMAC SHA256（写成 HS256）；typ属性表示这个令牌（token）的类型（type），JWT 令牌统一写为JWT。</p>

     <p>最后，将上面的 JSON 对象使用 Base64URL 算法（详见后文）转成字符串。</p>

     <p>3.2 Payload
       Payload 部分也是一个 JSON 对象，用来存放实际需要传递的数据。JWT 规定了7个官方字段，供选用。</p>

     <p>iss (issuer)：签发人
       exp (expiration time)：过期时间
       sub (subject)：主题
       aud (audience)：受众
       nbf (Not Before)：生效时间
       iat (Issued At)：签发时间
       jti (JWT ID)：编号
       除了官方字段，你还可以在这个部分定义私有字段，下面就是一个例子。</p>

     <p>javascript { &quot;sub&quot;: &quot;1234567890&quot;, &quot;name&quot;: &quot;John Doe&quot;, &quot;admin&quot;: true }
       注意，JWT 默认是不加密的，任何人都可以读到，所以不要把秘密信息放在这个部分。</p>

     <p>这个 JSON 对象也要使用 Base64URL 算法转成字符串。</p>

     <p>3.3 Signature
       Signature 部分是对前两部分的签名，防止数据篡改。</p>

     <p>首先，需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256），按照下面的公式产生签名。</p>

     <p>javascript HMACSHA256( base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload), secret)
       算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用&quot;点&quot;（.）分隔，就可以返回给用户。</p>

     <p>3.4 Base64URL
       前面提到，Header 和 Payload 串型化的算法是 Base64URL。这个算法跟 Base64 算法基本类似，但有一些小的不同。</p>

     <p>JWT 作为一个令牌（token），有些场合可能会放到 URL（比如 http://api.example.com/?token=xxx）。Base64 有三个字符+、/和=，在 URL 里面有特殊含义，所以要被替换掉：=被省略、+替换成-，/替换成_ 。这就是 Base64URL 算法。</p>

     <p>四、JWT 的使用方式
       客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。</p>

     <p>此后，客户端每次与服务器通信，都要带上这个 JWT。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息Authorization字段里面。</p>

     <p>javascript Authorization: Bearer &lt;token&gt;
       另一种做法是，跨域的时候，JWT 就放在 POST 请求的数据体里面。</p>

     <p>五、JWT 的几个特点
       （1）JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。</p>

     <p>（2）JWT 不加密的情况下，不能将秘密数据写入 JWT。</p>

     <p>（3）JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。</p>

     <p>（4）JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。</p>

     <p>（5）JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。</p>

     <p>（6）为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。</p>

    </p>
  </div>

   <div class="section" id="section12">
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
    <h2>接口限流</h2>
    <p>
       <p>使用<strong>注解、AOP和Redis</strong>来实现接口限流，限流算法采用简单计数器法，可以按照以下步骤进行：</p>

       <ol><li><p>创建一个自定义注解：通过<strong>创建一个自定义注解（例如<code>@RateLimit</code>）</strong>，<strong>用这个注解标记需要进行限流的接口方法。</strong></p></li><li><p>编写切面类：创建一个切面类，使用AOP技术拦截带有<code>@RateLimit</code>注解的方法。</p></li><li><p>切面逻辑实现：在切面类中，编写逻辑来实现接口的限流。具体步骤如下：</p><ul><li><p>使用类名加方法名作为标识符。</p><p>/<strong> 获取类名和方法名 </strong>/
           MethodSignature signature = (MethodSignature) point.getSignature();</p><pre><code> Method method = signature.getMethod();

 String[] classNameArray = method.getDeclaringClass().getName().split(&quot;\\.&quot;);

 String methodName = classNameArray[classNameArray.length - 1] + &quot;.&quot; + method.getName();

 String classZ = signature.getDeclaringTypeName();

 String countMapKey =  classZ + &quot;|&quot; + methodName;</code></pre></li><li><p>根据唯一标识符生成一个Redis的键，用于存储计数器的值。</p></li><li><p>使用Redis的<code>INCR</code>命令对该键的计数器进行自增操作，并设置过期时间。</p></li><li><p>获取计数器的当前值，如果超过了阈值（即达到了限流条件），则抛出自定义的限流异常。</p></li><li><p>如果未达到限流条件，则正常执行接口方法。</p></li></ul></li></ol>

    </div>

   <div class="section" id="section13">
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
    <h2>从架构层面优化性能</h2>
    <p>
       <p>MySQL处理高并发的业务时性能会出现问题，MySQL的处理性能会随着并发线程数上升而上升，但是到了一定的并发度之后会出现明显的拐点，之后一路下降，甚至会比单线程的性能还要差。</p>

       <p><strong>场景：</strong></p>

       <ol><li>在秒杀场景下，短时间内会有大量的请求同时进入系统，系统需要具备高并发处理能力，提供快速的响应。</li></ol>

       <p>分布式系统： 秒杀场景下，单台服务器扛不住请求高峰，分布式系统可以提高系统的容错能力和抗压能力，非常适合秒杀场景。</p>

       <p><strong>解决方案：</strong></p>

       <p>因为Redis的写性能和读性能都远高于MySQL，在MySQL之前前置一个Redis缓存，抢购活动开始前将关键数据提前加载到redis，之后的查询操作、写操作全部通过缓存实现，再将变化的数据放入消息队列，消费者根据MySQL的性能处理消息队列中的消息，将变化的数据异步写入到数据库中。</p>

       <p>通过这种方案，经过压力测试看到性能有了一个不小的提升。</p>

       <p>在这个方案中我自己还做了一些优化，虽然通过访问Redis已经很快了，但是还可以更快。在内存中用一个HashMap做标记，key为商品Id，value为true代表有库存，false代表没有库存，没有库存时直接返回下单失败信息，减少对Redis无意义的访问。</p>

       <p><strong>缺点：</strong></p>

       <ol><li>因为引入了缓存，所以又产生了数据库和缓存的数据不一致的风险。</li><li>缓存高可用。</li></ol>

    </p>

   <div class="section" id="section14">
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
    <h2></h2>
    <p>

    </p>
  </div>

   <div class="section" id="section15">
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
     <br>
    <h2>HashMap添加元素</h2>
    <p>


    </p>
  </div>

</div>
</div>
</body>
</html>